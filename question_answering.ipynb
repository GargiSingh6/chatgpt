{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import whisper\n",
        "from pytube import YouTube\n",
        "import requests\n",
        "import base64\n",
        "import numpy as np\n",
        "import openai\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import tiktoken\n",
        "from typing import List\n",
        "import codecs\n",
        "import nltk\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "import io\n",
        "import math\n",
        "import requests\n",
        "COMPLETIONS_MODEL = \"text-davinci-003\"\n",
        "EMBEDDING_MODEL = \"text-embedding-ada-002\"\n",
        "openai.api_key = \"\""
      ],
      "metadata": {
        "id": "F886z81pZKm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bk_zLbccY-ay"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "#download punkt package\n",
        "nltk.download()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def youtube_to_transcript(link):\n",
        "    model = whisper.load_model(\"large\")\n",
        "    yt = YouTube(link)\n",
        "    path = yt.streams.filter(only_audio=True)[0].download(filename=\"audio.mp4\")\n",
        "    options = whisper.DecodingOptions(without_timestamps=True)\n",
        "    transcription = model.transcribe(path)\n",
        "    return transcription[\"text\"]"
      ],
      "metadata": {
        "id": "N7vsvKIeZTv7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_embedding(text: str, model: str=EMBEDDING_MODEL) -> List[float]:\n",
        "    result = openai.Embedding.create(\n",
        "      model=model,\n",
        "      input=text\n",
        "    )\n",
        "    return result[\"data\"][0][\"embedding\"]\n",
        "def vector_similarity(x: List[float], y: List[float]) -> float:\n",
        "    return np.dot(np.array(x), np.array(y))"
      ],
      "metadata": {
        "id": "RP4bmKYFZe7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getchunks(string):\n",
        "    tokens = nltk.word_tokenize(string)\n",
        "    num_tokens = len(tokens)\n",
        "    print(num_tokens)\n",
        "    if num_tokens <= 3000:\n",
        "        return [string]\n",
        "    max_chunk_size = 2500\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < num_tokens:\n",
        "        end = start + max_chunk_size\n",
        "        if end >= num_tokens:\n",
        "            end = num_tokens\n",
        "       \n",
        "        chunks.append(' '.join(tokens[start:end]))\n",
        "        \n",
        "        start = end\n",
        "        \n",
        "    return chunks"
      ],
      "metadata": {
        "id": "ZxtwQ2wEZl8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getresponse(context,query):\n",
        "    prompt = f\"Answer the question as concisely as possible using the provided context:. question: {query} context:{context}\"\n",
        "    params = {\n",
        "        \"engine\": \"text-davinci-003\",\n",
        "        \"prompt\": prompt,\n",
        "        \"temperature\": 0.0,\n",
        "        \"max_tokens\": 500,\n",
        "    }\n",
        "    response = openai.Completion.create(**params)\n",
        "    return response[\"choices\"][0][\"text\"].strip(\" \\n\")"
      ],
      "metadata": {
        "id": "BG6dSTZzZoyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def final_wrapper(transcript,query):\n",
        "    documents=getchunks(transcript)#returns list of chunks\n",
        "    document_embed=[]\n",
        "    for i in documents:\n",
        "        document_embed.append(get_embedding(i))\n",
        "    query_embed=get_embedding(query)\n",
        "    similarity=[]\n",
        "    for i in document_embed:\n",
        "        similarity.append(vector_similarity(i,query_embed))\n",
        "    max_index = similarity.index(max(similarity))\n",
        "    context=documents[max_index]\n",
        "    return getresponse(context,query)"
      ],
      "metadata": {
        "id": "LjWMy4AgZq44"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#insert a youtube link and your query here\n",
        "link=\"\"\n",
        "query=\"\""
      ],
      "metadata": {
        "id": "AxCmCAHiZrkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_wrapper(youtube_to_transcript(link),query)"
      ],
      "metadata": {
        "id": "X7WsQ3_yZujS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}